{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to TableVault","text":"<p>TableVault is a centralized data repository backed by ArangoDB that enables cross-process data filtering between multiple Python scripts and notebooks.</p> <p>TableVault can search over stored data items (e.g., dataframe rows, embeddings, documents) by name, exact matches, token matches, or vector similarity. These items can be filtered by the original generating code, text and embedding descriptions, or upstream and downstream items.</p> <p>Using TableVault, Python processes can send requests to other ongoing processes to \"stop\", \"pause\", and \"continue\". Communication is backed by the centralized data repository, and \"stop\" and \"pause\" actions are guaranteed to occur only at user-defined checkpoints.</p> <p>Applications include fast comparisons of agentic and ML workflows across many experiments. For example, across variations of a RAG workflow, TableVault can perform longitudinal queries to compare accuracy scores when using different language model prompts.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install via pip:</p> <pre><code>pip install tablevault\n</code></pre>"},{"location":"api/core_api/","title":"Core API Reference","text":"<p>The <code>Vault</code> class is the main interface for tracking ML items and their lineage.</p>"},{"location":"api/core_api/#initialization","title":"Initialization","text":""},{"location":"api/core_api/#vault","title":"<code>Vault</code>","text":"<pre><code>Vault(\n    user_id: str,\n    process_name: str,\n    parent_process_name: str = \"\",\n    parent_process_index: int = 0,\n    arango_url: str = \"http://localhost:8529\",\n    arango_db: str = \"tablevault\",\n    arango_username: str = \"tablevault_user\",\n    arango_password: str = \"tablevault_password\",\n    new_arango_db: bool = True,\n    arango_root_username: str = \"root\",\n    arango_root_password: str = \"passwd\",\n    description_embedding_size: int = 1024,\n    log_file_location: str = \"~/.tablevault/logs/\",\n) -&gt; Vault\n</code></pre> <p>Initialize the Vault singleton. Only one vault can be active per Python process. Once active, all subsequently executed code is tracked in the TableVault repository.</p> <p>Parameters:</p> Name Type Description <code>user_id</code> <code>str</code> Unique identifier for the user <code>process_name</code> <code>str</code> Unique name for this process <code>parent_process_name</code> <code>str</code> Name of the generating process (if exists) <code>parent_process_index</code> <code>int</code> Index of the generating process (if exists) <code>arango_url</code> <code>str</code> URL of the ArangoDB server <code>arango_db</code> <code>str</code> Name of the database to use <code>arango_username</code> <code>str</code> Username for database access <code>arango_password</code> <code>str</code> Password for database access <code>new_arango_db</code> <code>bool</code> If True, create a new database (drops existing) <code>arango_root_username</code> <code>str</code> Root username for database creation <code>arango_root_password</code> <code>str</code> Root password for database creation <code>description_embedding_size</code> <code>int</code> Dimension of description embeddings <code>log_file_location</code> <code>str</code> Directory for log files <p>Returns: <code>Vault</code> instance</p>"},{"location":"api/core_api/#create-functions","title":"Create Functions","text":"<p>Functions for creating new item lists.</p>"},{"location":"api/core_api/#create_file_list","title":"<code>create_file_list</code>","text":"<pre><code>create_file_list(item_name: str) -&gt; None\n</code></pre> <p>Create a new file list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Unique name for the file list"},{"location":"api/core_api/#create_document_list","title":"<code>create_document_list</code>","text":"<pre><code>create_document_list(item_name: str) -&gt; None\n</code></pre> <p>Create a new document list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Unique name for the document list"},{"location":"api/core_api/#create_embedding_list","title":"<code>create_embedding_list</code>","text":"<pre><code>create_embedding_list(item_name: str, ndim: int) -&gt; None\n</code></pre> <p>Create a new embedding list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Unique name for the embedding list <code>ndim</code> <code>int</code> Dimensionality of the embeddings in this list"},{"location":"api/core_api/#create_record_list","title":"<code>create_record_list</code>","text":"<pre><code>create_record_list(item_name: str, column_names: List[str]) -&gt; None\n</code></pre> <p>Create a new record list with specified column names.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Unique name for the record list <code>column_names</code> <code>List[str]</code> List of column names for records in this list"},{"location":"api/core_api/#create_description","title":"<code>create_description</code>","text":"<pre><code>create_description(\n    item_name: str,\n    description: str,\n    embedding: List[float],\n    description_name: str = \"BASE\"\n) -&gt; None\n</code></pre> <p>Adds a joint text and embedding description to an item list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item to describe <code>description</code> <code>str</code> Text description of the item <code>embedding</code> <code>List[float]</code> Embedding vector for the description <code>description_name</code> <code>str</code> Label for this description (default \"BASE\")"},{"location":"api/core_api/#append-functions","title":"Append Functions","text":"<p>Functions for appending content to existing item lists.</p>"},{"location":"api/core_api/#append_file","title":"<code>append_file</code>","text":"<pre><code>append_file(\n    item_name: str,\n    location: str,\n    input_items: Optional[InputItems] = None,\n    index: Optional[int] = None\n) -&gt; None\n</code></pre> <p>Append a file reference to a file list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the file list to append to <code>location</code> <code>str</code> File path or location string <code>input_items</code> <code>Optional[InputItems]</code> Mapping of dependency item key \u2192 [start_position, end_position] <code>index</code> <code>Optional[int]</code> Specific index to insert at (appends to end if None)"},{"location":"api/core_api/#append_document","title":"<code>append_document</code>","text":"<pre><code>append_document(\n    item_name: str,\n    text: str,\n    input_items: Optional[InputItems] = None,\n    index: Optional[int] = None,\n    start_position: Optional[int] = None\n) -&gt; None\n</code></pre> <p>Append a text chunk to a document list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the document list to append to <code>text</code> <code>str</code> Text content of the document <code>input_items</code> <code>Optional[InputItems]</code> Mapping of dependency item key \u2192 [start_position, end_position] <code>index</code> <code>Optional[int]</code> Specific index to insert at (appends to end if None) <code>start_position</code> <code>Optional[int]</code> Character position within the document stream <p>Note</p> <p>Both <code>index</code> and <code>start_position</code> must be provided together when specifying manual positions.</p>"},{"location":"api/core_api/#append_embedding","title":"<code>append_embedding</code>","text":"<pre><code>append_embedding(\n    item_name: str,\n    embedding: List[float],\n    input_items: Optional[InputItems] = None,\n    index: Optional[int] = None,\n    build_idx: bool = True,\n    index_rebuild_count: int = 10000\n) -&gt; None\n</code></pre> <p>Append an embedding vector to an embedding list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the embedding list to append to <code>embedding</code> <code>List[float]</code> The embedding vector to store <code>input_items</code> <code>Optional[InputItems]</code> Mapping of dependency item key \u2192 [start_position, end_position] <code>index</code> <code>Optional[int]</code> Specific index to insert at (appends to end if None) <code>build_idx</code> <code>bool</code> Whether to rebuild the vector index <code>index_rebuild_count</code> <code>int</code> Threshold for triggering index rebuild"},{"location":"api/core_api/#append_record","title":"<code>append_record</code>","text":"<pre><code>append_record(\n    item_name: str,\n    record: Dict[str, Any],\n    input_items: Optional[InputItems] = None,\n    index: Optional[int] = None\n) -&gt; None\n</code></pre> <p>Append a record (row) to a record list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the record list to append to <code>record</code> <code>Dict[str, Any]</code> Dictionary with column names as keys and values <code>input_items</code> <code>Optional[InputItems]</code> Mapping of dependency item key \u2192 [start_position, end_position] <code>index</code> <code>Optional[int]</code> Specific index to insert at (appends to end if None) <p>Note</p> <p>Top-level dictionary keys must match the initial column names defined when the record list was created.</p>"},{"location":"api/core_api/#operation-management","title":"Operation Management","text":"<p>Functions for managing vault operations and cleanup.</p>"},{"location":"api/core_api/#get_current_operations","title":"<code>get_current_operations</code>","text":"<pre><code>get_current_operations() -&gt; Dict[str, Any]\n</code></pre> <p>Get all currently active operations.</p> <p>Returns: Dictionary of active operation timestamps</p>"},{"location":"api/core_api/#vault_cleanup","title":"<code>vault_cleanup</code>","text":"<pre><code>vault_cleanup(\n    interval: int = 60,\n    selected_timestamps: Optional[List[int]] = None\n) -&gt; None\n</code></pre> <p>Clean up stale operations that have exceeded the interval.</p> <p>Parameters:</p> Name Type Description <code>interval</code> <code>int</code> Time in seconds after which an operation is considered stale <code>selected_timestamps</code> <code>Optional[List[int]]</code> If provided, only clean up these specific timestamps"},{"location":"api/core_api/#process-control","title":"Process Control","text":"<p>Functions for controlling process execution lifecycle.</p>"},{"location":"api/core_api/#checkpoint_execution","title":"<code>checkpoint_execution</code>","text":"<pre><code>checkpoint_execution() -&gt; None\n</code></pre> <p>Mark a safe checkpoint in code where stop and pause requests can be executed. This avoids stopping during undesirable conditions (e.g., while waiting for outgoing API calls).</p>"},{"location":"api/core_api/#pause_execution","title":"<code>pause_execution</code>","text":"<pre><code>pause_execution(process_name: str) -&gt; None\n</code></pre> <p>Request to pause another process's execution.</p> <p>Parameters:</p> Name Type Description <code>process_name</code> <code>str</code> Name of the process to pause"},{"location":"api/core_api/#stop_execution","title":"<code>stop_execution</code>","text":"<pre><code>stop_execution(process_name: str) -&gt; None\n</code></pre> <p>Request to stop another process's execution.</p> <p>Parameters:</p> Name Type Description <code>process_name</code> <code>str</code> Name of the process to stop"},{"location":"api/core_api/#resume_execution","title":"<code>resume_execution</code>","text":"<pre><code>resume_execution(process_name: str) -&gt; None\n</code></pre> <p>Resume a paused process by name.</p> <p>Parameters:</p> Name Type Description <code>process_name</code> <code>str</code> Name of the process list to resume <p>Note</p> <p>Currently only works when processes are on the same machine or container.</p>"},{"location":"api/core_api/#delete-functions","title":"Delete Functions","text":"<p>Functions for deleting item lists.</p>"},{"location":"api/core_api/#delete_list","title":"<code>delete_list</code>","text":"<pre><code>delete_list(item_name: str) -&gt; None\n</code></pre> <p>Delete an item list's content.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list to delete"},{"location":"api/core_api/#utility-functions","title":"Utility Functions","text":"<p>Helper functions for checking vault state.</p>"},{"location":"api/core_api/#has_vector_index","title":"<code>has_vector_index</code>","text":"<pre><code>has_vector_index(ndim: int) -&gt; bool\n</code></pre> <p>Check if a vector index exists for embeddings of a given dimension.</p> <p>Parameters:</p> Name Type Description <code>ndim</code> <code>int</code> Dimensionality of the embeddings <p>Returns: <code>True</code> if a vector index exists for this dimension</p>"},{"location":"api/core_api/#list-queries","title":"List Queries","text":"<p>Functions for querying across item lists with filtering and similarity search.</p>"},{"location":"api/core_api/#query_process_list","title":"<code>query_process_list</code>","text":"<pre><code>query_process_list(\n    code_text: Optional[str] = None,\n    parent_code_text: Optional[str] = None,\n    description_embedding: Optional[List[float]] = None,\n    description_text: Optional[str] = None,\n    filtered: Optional[List[str]] = None\n) -&gt; List[Any]\n</code></pre> <p>Query process items. Can optionally filter by descriptions and parent process.</p> <p>Parameters:</p> Name Type Description <code>code_text</code> <code>Optional[str]</code> Text to search in process code <code>parent_code_text</code> <code>Optional[str]</code> Text to search in parent process code <code>description_embedding</code> <code>Optional[List[float]]</code> Embedding vector for similarity search <code>description_text</code> <code>Optional[str]</code> Text to search in descriptions <code>filtered</code> <code>Optional[List[str]]</code> List of process names to restrict search to <p>Returns: List of matching process results</p>"},{"location":"api/core_api/#query_embedding_list","title":"<code>query_embedding_list</code>","text":"<pre><code>query_embedding_list(\n    embedding: List[float],\n    description_embedding: Optional[List[float]] = None,\n    description_text: Optional[str] = None,\n    code_text: Optional[str] = None,\n    filtered: Optional[List[str]] = None,\n    use_approx: bool = False\n) -&gt; List[Any]\n</code></pre> <p>Query embedding items. Can optionally filter by descriptions and parent process.</p> <p>Parameters:</p> Name Type Description <code>embedding</code> <code>List[float]</code> Query embedding vector for similarity search <code>description_embedding</code> <code>Optional[List[float]]</code> Embedding for description similarity <code>description_text</code> <code>Optional[str]</code> Text to search in descriptions <code>code_text</code> <code>Optional[str]</code> Text to search in process code <code>filtered</code> <code>Optional[List[str]]</code> List of embedding names to restrict search to <code>use_approx</code> <code>bool</code> Use approximate (faster) similarity search <p>Returns: List of matching embedding results</p>"},{"location":"api/core_api/#query_record_list","title":"<code>query_record_list</code>","text":"<pre><code>query_record_list(\n    record_text: str,\n    description_embedding: Optional[List[float]] = None,\n    description_text: Optional[str] = None,\n    code_text: Optional[str] = None,\n    filtered: Optional[List[str]] = None\n) -&gt; List[Any]\n</code></pre> <p>Query record items. Can optionally filter by descriptions and parent process.</p> <p>Parameters:</p> Name Type Description <code>record_text</code> <code>str</code> Text to search in record data <code>description_embedding</code> <code>Optional[List[float]]</code> Embedding for description similarity <code>description_text</code> <code>Optional[str]</code> Text to search in descriptions <code>code_text</code> <code>Optional[str]</code> Text to search in process code <code>filtered</code> <code>Optional[List[str]]</code> List of record names to restrict search to <p>Returns: List of matching record results</p>"},{"location":"api/core_api/#query_document_list","title":"<code>query_document_list</code>","text":"<pre><code>query_document_list(\n    document_text: str,\n    description_embedding: Optional[List[float]] = None,\n    description_text: Optional[str] = None,\n    code_text: Optional[str] = None,\n    filtered: Optional[List[str]] = None\n) -&gt; List[Any]\n</code></pre> <p>Query document items. Can optionally filter by descriptions and parent process.</p> <p>Parameters:</p> Name Type Description <code>document_text</code> <code>str</code> Text to search in document content <code>description_embedding</code> <code>Optional[List[float]]</code> Embedding for description similarity <code>description_text</code> <code>Optional[str]</code> Text to search in descriptions <code>code_text</code> <code>Optional[str]</code> Text to search in process code <code>filtered</code> <code>Optional[List[str]]</code> List of document names to restrict search to <p>Returns: List of matching document item results</p>"},{"location":"api/core_api/#query_file_list","title":"<code>query_file_list</code>","text":"<pre><code>query_file_list(\n    description_embedding: Optional[List[float]] = None,\n    description_text: Optional[str] = None,\n    code_text: Optional[str] = None,\n    filtered: Optional[List[str]] = None\n) -&gt; List[Any]\n</code></pre> <p>Query file items. Can optionally filter by descriptions and parent process.</p> <p>Parameters:</p> Name Type Description <code>description_embedding</code> <code>Optional[List[float]]</code> Embedding for description similarity <code>description_text</code> <code>Optional[str]</code> Text to search in descriptions <code>code_text</code> <code>Optional[str]</code> Text to search in process code <code>filtered</code> <code>Optional[List[str]]</code> List of file names to restrict search to <p>Returns: List of matching file item results</p>"},{"location":"api/core_api/#basic-queries","title":"Basic Queries","text":"<p>Functions for querying individual items and their relationships.</p>"},{"location":"api/core_api/#query_item_content","title":"<code>query_item_content</code>","text":"<pre><code>query_item_content(\n    item_name: str,\n    index: Optional[int] = None,\n    start_position: Optional[int] = None,\n    end_position: Optional[int] = None\n) -&gt; Any\n</code></pre> <p>Query the content of an item list by index chunk or position range.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list to query <code>index</code> <code>Optional[int]</code> Specific index chunk to retrieve <code>start_position</code> <code>Optional[int]</code> Start of position range (if index not specified) <code>end_position</code> <code>Optional[int]</code> End of position range (if index not specified) <p>Returns: The item content at the specified index or position range</p>"},{"location":"api/core_api/#query_item_list","title":"<code>query_item_list</code>","text":"<pre><code>query_item_list(item_name: str) -&gt; Dict[str, Any]\n</code></pre> <p>Get metadata for an item list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list <p>Returns: Dictionary with list metadata (n_items, length, etc.)</p>"},{"location":"api/core_api/#query_item_parent","title":"<code>query_item_parent</code>","text":"<pre><code>query_item_parent(\n    item_name: str,\n    start_position: Optional[int] = None,\n    end_position: Optional[int] = None\n) -&gt; List[Any]\n</code></pre> <p>Query input dependencies of an item list. Allows optional position filtering.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list <code>start_position</code> <code>Optional[int]</code> Filter by start position <code>end_position</code> <code>Optional[int]</code> Filter by end position <p>Returns: List of item list information</p>"},{"location":"api/core_api/#query_item_child","title":"<code>query_item_child</code>","text":"<pre><code>query_item_child(\n    item_name: str,\n    start_position: Optional[int] = None,\n    end_position: Optional[int] = None\n) -&gt; List[Any]\n</code></pre> <p>Query items that depend on an item list. Allows optional position filtering.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list <code>start_position</code> <code>Optional[int]</code> Filter by start position <code>end_position</code> <code>Optional[int]</code> Filter by end position <p>Returns: List of child item information</p>"},{"location":"api/core_api/#query_item_description","title":"<code>query_item_description</code>","text":"<pre><code>query_item_description(item_name: str) -&gt; List[str]\n</code></pre> <p>Get descriptions associated with an item list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list <p>Returns: List of description texts</p>"},{"location":"api/core_api/#query_item_creation_process","title":"<code>query_item_creation_process</code>","text":"<pre><code>query_item_creation_process(item_name: str) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Get the process that created an item list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list <p>Returns: List of process information with process_id and index</p>"},{"location":"api/core_api/#query_item_process","title":"<code>query_item_process</code>","text":"<pre><code>query_item_process(\n    item_name: str,\n    start_position: Optional[int] = None,\n    end_position: Optional[int] = None\n) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Get processes that modified an item list. Can filter by position range within the list.</p> <p>Parameters:</p> Name Type Description <code>item_name</code> <code>str</code> Name of the item list <code>start_position</code> <code>Optional[int]</code> Filter by start position <code>end_position</code> <code>Optional[int]</code> Filter by end position <p>Returns: List of process info dicts with process name and index</p>"},{"location":"api/core_api/#query_process_item","title":"<code>query_process_item</code>","text":"<pre><code>query_process_item(process_name: str) -&gt; List[Dict[str, Any]]\n</code></pre> <p>Get all items created or modified by a given process name.</p> <p>Parameters:</p> Name Type Description <code>process_name</code> <code>str</code> Name of the process list <p>Returns: List of item dictionaries with name and position range</p>"},{"location":"api/description_functions/","title":"Description API Reference","text":"<p>Description operations are currently documented in the main API page:</p> <ul> <li><code>create_description</code> in <code>docs/api/core_api.md</code></li> <li><code>query_item_description</code> in <code>docs/api/core_api.md</code></li> </ul> <p>This page is reserved for a dedicated description-focused API reference in a future update.</p>"},{"location":"concepts/descriptions/","title":"Descriptions","text":"<p>Each item list can store multiple descriptions with semantic metadata. Each description must include both text and an embedding vector. The embedding dimension must match the value configured when the TableVault repository was created.</p> <pre><code>description = \"Full novel of Frankenstein by Mary Shelley in paragraphs\"\nembedding = MODEL(description)\n\nvault.create_description(\"frankenstein_novel\", description, embedding)\n</code></pre> <p>When querying item types, you can filter by token search over description text or vector similarity over description embeddings.</p>"},{"location":"concepts/descriptions/#ai-generated-descriptions","title":"AI Generated Descriptions","text":"<p>Automatic description and embedding generation may be added in a future release. If this is useful for your workflow, please free to reach out!</p>"},{"location":"concepts/lists/","title":"Item Lists","text":"<p>Each data item in TableVault is stored in an ordered collection called an item list. Multiple processes may incrementally append data to a list as long as the data matches the list constraints. Data items within a list can be identified by their position and index values, or found through search matches.</p> <p>For example, we can store the text of a novel, such as \"Frankenstein\", as a document list. If we store each paragraph as a data item, we can find the third paragraph by paragraph index (e.g., 2), character/position offset (e.g., 2494), or text match (e.g., \"These reflections have dispelled the agitation\").</p> <p>We can also store a list of vector embeddings, such as embeddings generated from \"ImageNet\", as an embedding list. We can find an embedding by index/position (e.g., 2) in the list, or by vector similarity match (e.g., an embedding that matches the vector).</p>"},{"location":"concepts/lists/#item-list-creation","title":"Item List Creation","text":"<p>Once a Vault object has been created (see Repository Setup), each item list can be created by defining the item type and a unique name.</p> <p>Unique Names</p> <p>Note that names must be unique across all item types and processes. Once a name is used as an item list, it currently cannot be reused, even if the data is later deleted.</p> <p><pre><code># Example: Create a document list\nvault.create_document_list(\"frankenstein_novel\")\n\n# Example: Create an embedding list\nvault.create_embedding_list(\"image_net_embeddings\", ndim=1024)\n</code></pre> An embedding list has an extra constraint that the length of all embeddings must be the same.</p>"},{"location":"concepts/lists/#appending-items","title":"Appending Items","text":"<p>Once a list has been defined in a TableVault repository, any process can append data to the list.</p> <pre><code># Example: Add a Frankenstein paragraph to frankenstein_novel\nvault.append_document(\n    \"frankenstein_novel\",\n    text=\"These reflections have dispelled the agitation...\",\n)\n\n# Example: Add a generated embedding to image_net_embeddings\nembedding = MODEL(image)\nvault.append_embedding(\"image_net_embeddings\", embedding)\n</code></pre> <p>Opportunistic locking ensures that each item is appended atomically. In a single process, the stored order is the same as the appending order. With concurrent processes, you can use the <code>index</code> parameter to define absolute ordering if necessary.</p>"},{"location":"concepts/lists/#input-item-parameters","title":"Input Item Parameters","text":"<p>When you are appending a data item, you can define the input items that contributed to the generation of that item. This allows for more powerful queries, since you can subsequently query for lineage between items.</p> <p>For example, if you have previously stored an index of ImageNet images as a file list, you can link that index to the generated embedding list.</p> <pre><code>image_files = vault.query_item_content(\"image_net_files\")\n\nfor index, image_file in enumerate(image_files):\n    image = GET_IMAGE(image_file)  # placeholder function\n    embedding = MODEL(image)  # placeholder model\n    input_items = {\"image_net_files\": [index, index + 1]}\n    vault.append_embedding(\n        \"image_net_embeddings\",\n        embedding,\n        input_items=input_items,\n    )\n</code></pre> <p>Here <code>[index, index + 1]</code> represents the start and end position of the relevant data inside <code>image_net_files</code>.</p>"},{"location":"concepts/lists/#basic-item-list-queries","title":"Basic Item List Queries","text":"<p>See Item List Queries for more information.</p>"},{"location":"concepts/lists/#basic-item-list-types","title":"Basic Item List Types","text":"<p>Currently, we support the following types: files, documents, embeddings, and records. See Item List Types for more information.</p>"},{"location":"concepts/process/","title":"Process Management","text":"<p>TableVault provides mechanisms for coordinating execution between multiple Python processes. This enables workflows where one process can request another to stop or pause at safe checkpoints.</p>"},{"location":"concepts/process/#process-overview","title":"Process Overview","text":"<p>When you create a <code>Vault</code> object, TableVault automatically:</p> <ol> <li>Creates a process record in the database</li> <li>Tracks the process ID (PID) of the running Python process</li> <li>Records all executed code (cells in notebooks, full scripts for scripts)</li> <li>Monitors for interrupt requests from other processes</li> </ol>"},{"location":"concepts/process/#process-types","title":"Process Types","text":"<p>TableVault distinguishes between two execution types:</p> <ul> <li>Notebook processes: Each cell execution is recorded as a separate item</li> <li>Script processes: The entire script is recorded as a single item</li> </ul> <p>The process type is automatically detected based on your execution environment.</p>"},{"location":"concepts/process/#cross-process-communication","title":"Cross-Process Communication","text":"<p>Processes can send control requests to other running processes. This is useful for:</p> <ul> <li>Stopping long-running experiments</li> <li>Pausing data processing pipelines</li> <li>Coordinating parallel ML workflows</li> </ul>"},{"location":"concepts/process/#requesting-stop","title":"Requesting Stop","text":"<p>Stop a process by name:</p> <pre><code># In process A\nvault.stop_execution(\"experiment_process\")\n</code></pre> <p>The target process will terminate at its next checkpoint.</p>"},{"location":"concepts/process/#requesting-pause","title":"Requesting Pause","text":"<p>Pause a process (can be resumed later):</p> <pre><code># In process A\nvault.pause_execution(\"data_pipeline\")\n</code></pre> <p>The target process will suspend at its next checkpoint.</p>"},{"location":"concepts/process/#resuming-a-paused-process","title":"Resuming a Paused Process","text":"<p>Resume a previously paused process:</p> <pre><code># In process A\nvault.resume_execution(\"data_pipeline\")\n</code></pre> <p>Single Machine Limitation</p> <p>Resume functionality currently only works when all processes are running on the same machine/container, as it uses process signals.</p>"},{"location":"concepts/process/#checkpoints","title":"Checkpoints","text":"<p>Control requests (stop/pause) are only executed at checkpoints. This ensures that:</p> <ul> <li>Operations complete atomically</li> <li>API calls aren't interrupted mid-flight</li> <li>Database transactions finish properly</li> </ul>"},{"location":"concepts/process/#defining-checkpoints","title":"Defining Checkpoints","text":"<p>Add checkpoints in your code where it's safe to stop:</p> <pre><code>for batch in data_batches:\n    # Process batch\n    results = process_batch(batch)\n    vault.append_record(\"results\", results)\n\n    # Safe point to check for stop/pause requests\n    vault.checkpoint_execution()\n</code></pre>"},{"location":"concepts/process/#checkpoint-behavior","title":"Checkpoint Behavior","text":"<p>When a checkpoint is reached:</p> <ol> <li>TableVault checks for pending interrupt requests</li> <li>If a pause request exists: the process is suspended</li> <li>If a stop request exists: the process is terminated</li> <li>If no requests exist: execution continues normally</li> </ol>"},{"location":"concepts/process/#example-coordinated-ml-workflow","title":"Example: Coordinated ML Workflow","text":""},{"location":"concepts/process/#main-controller-process","title":"Main Controller Process","text":"<pre><code>from tablevault import Vault\n\nvault = Vault(\n    user_id=\"researcher\",\n    process_name=\"controller\",\n    new_arango_db=False\n)\n\n# Check status of running experiments\noperations = vault.get_current_operations()\nprint(f\"Active operations: {operations}\")\n\n# Stop an experiment that's taking too long\nvault.stop_execution(\"slow_experiment\")\n\n# Pause data ingestion while we analyze\nvault.pause_execution(\"data_ingestion\")\n\n# ... do analysis ...\n\n# Resume data ingestion\nvault.resume_execution(\"data_ingestion\")\n</code></pre>"},{"location":"concepts/process/#worker-process","title":"Worker Process","text":"<pre><code>from tablevault import Vault\n\nvault = Vault(\n    user_id=\"researcher\",\n    process_name=\"slow_experiment\",\n    new_arango_db=False\n)\n\nfor epoch in range(1000):\n    # Training loop\n    loss = train_epoch(model, data)\n\n    # Record results\n    vault.append_record(\"training_logs\", {\n        \"epoch\": epoch,\n        \"loss\": loss\n    })\n\n    # Checkpoint: safe to stop/pause here\n    vault.checkpoint_execution()\n</code></pre>"},{"location":"concepts/process/#parent-child-process-relationships","title":"Parent-Child Process Relationships","text":"<p>Processes can be linked in a parent-child hierarchy. This is useful when one script spawns others:</p> <pre><code># Parent process\nparent_vault = Vault(\n    user_id=\"researcher\",\n    process_name=\"hyperparameter_search\"\n)\n\n# ... spawn child processes ...\n</code></pre> <pre><code># Child process (spawned by parent)\nchild_vault = Vault(\n    user_id=\"researcher\",\n    process_name=\"experiment_run_1\",\n    parent_process_name=\"hyperparameter_search\",\n    parent_process_index=0  # Index in parent's code\n)\n</code></pre> <p>This relationship enables:</p> <ul> <li>Querying processes by parent code (<code>parent_code_text</code> parameter)</li> <li>Understanding experiment provenance</li> <li>Tracking which parent spawned which experiments</li> </ul>"},{"location":"concepts/process/#cleanup-operations","title":"Cleanup Operations","text":"<p>If processes crash or exit unexpectedly, operations may remain incomplete. Use cleanup to recover:</p> <pre><code># Clean up operations older than 60 seconds\nvault.vault_cleanup(interval=60)\n\n# Clean up specific timestamps\nvault.vault_cleanup(selected_timestamps=[1234567890, 1234567891])\n</code></pre>"},{"location":"concepts/process/#querying-processes","title":"Querying Processes","text":"<p>Find processes based on various criteria:</p> <pre><code># Find processes by code content\nprocesses = vault.query_process_list(code_text=\"import pandas\")\n\n# Find processes by parent code\nprocesses = vault.query_process_list(parent_code_text=\"spawn_worker\")\n\n# Find processes by description\nprocesses = vault.query_process_list(description_text=\"training pipeline\")\n\n# Combine filters\nprocesses = vault.query_process_list(\n    code_text=\"model.fit\",\n    parent_code_text=\"hyperparameter_search\",\n    filtered=[\"exp_1\", \"exp_2\", \"exp_3\"]\n)\n</code></pre>"},{"location":"concepts/process/#error-handling","title":"Error Handling","text":"<p>Processes automatically record errors:</p> <ul> <li>In scripts: Uncaught exceptions are captured</li> <li>In notebooks: Cell errors are captured</li> </ul> <p>This information is stored with the process code and can be queried for debugging.</p>"},{"location":"concepts/queries/","title":"Basic Queries","text":"<p>TableVault provides a set of query functions for exploring individual item lists and their relationships. These queries enable you to trace data lineage, understand how items were created, and retrieve specific portions of data.</p>"},{"location":"concepts/queries/#querying-item-content","title":"Querying Item Content","text":"<p>Retrieve the actual data stored in an item list using <code>query_item_content</code>. You can fetch by index (chunk number) or by position range.</p> <pre><code># Get content at a specific index\ncontent = vault.query_item_content(\"document_chunks\", index=0)\n\n# Get content within a position range\ncontent = vault.query_item_content(\"document_chunks\", start_position=0, end_position=500)\n\n# Get all content (no filters)\nall_content = vault.query_item_content(\"document_chunks\")\n</code></pre>"},{"location":"concepts/queries/#item-metadata","title":"Item Metadata","text":"<p>Get metadata about an item list using <code>query_item_list</code>:</p> <pre><code># Get metadata for an item list\nmetadata = vault.query_item_list(\"experiment_results\")\n# Returns: {\"n_items\": 50, \"length\": 1000, ...}\n</code></pre>"},{"location":"concepts/queries/#python-lineage-tracking","title":"Python Lineage Tracking","text":"<p>Every operation in TableVault is automatically tied to a Python process. You can query the relationship between items and processes.</p>"},{"location":"concepts/queries/#finding-the-creation-process","title":"Finding the Creation Process","text":"<p>Get the process that originally created an item list:</p> <pre><code># Find which process created this item\ncreation_info = vault.query_item_creation_process(\"experiment_results\")\n# Returns: [{\"process_id\": \"training_run_01\", \"index\": 3}]\n</code></pre>"},{"location":"concepts/queries/#finding-all-modifying-processes","title":"Finding All Modifying Processes","text":"<p>Get all processes that have modified an item list, optionally filtered by position:</p> <pre><code># Get all processes that modified this item\nprocesses = vault.query_item_process(\"document_chunks\")\n\n# Get processes that modified only a specific range\nprocesses = vault.query_item_process(\n    \"document_chunks\",\n    start_position=0,\n    end_position=500\n)\n# Useful when different processes appended different portions\n</code></pre>"},{"location":"concepts/queries/#finding-items-from-a-python-process","title":"Finding Items from a Python Process","text":"<p>Get all items that a process created or modified:</p> <pre><code># Get all items touched by a process\nitems = vault.query_process_item(\"data_pipeline_process\")\n# Returns: [{\"name\": \"raw_data\", \"start\": 0, \"end\": 1000}, ...]\n</code></pre>"},{"location":"concepts/queries/#data-lineage-tracking","title":"Data Lineage Tracking","text":"<p>When you specify <code>input_items</code> during append operations, these dependencies are also stored and can be queried later.</p>"},{"location":"concepts/queries/#querying-dependencies","title":"Querying Dependencies","text":"<p>Find what items a given item depends on using <code>query_item_parent</code>:</p> <pre><code># Get all input dependencies for an embedding list\nparents = vault.query_item_parent(\"document_embeddings\")\n# Returns items that \"document_embeddings\" was derived from\n\n# Filter by position range within the item\n# Find inputs for only positions 0-100 of the embedding list\nparents = vault.query_item_parent(\n    \"document_embeddings\",\n    start_position=0,\n    end_position=100\n)\n</code></pre>"},{"location":"concepts/queries/#querying-child-items","title":"Querying Child Items","text":"<p>Find what items were derived from a given item using <code>query_item_child</code>:</p> <pre><code># Get all items that depend on this document list\nchildren = vault.query_item_child(\"raw_documents\")\n# Returns items like embeddings, summaries, etc. derived from raw_documents\n\n# Filter by position range\n# Find items derived from only positions 50-150 of the source\nchildren = vault.query_item_child(\n    \"raw_documents\",\n    start_position=50,\n    end_position=150\n)\n</code></pre>"},{"location":"concepts/queries/#item-list-descriptions","title":"Item List Descriptions","text":"<p>You can also retrieve descriptions associated with an item list:</p> <pre><code># Get all descriptions for an item\ndescriptions = vault.query_item_description(\"trained_models\")\n# Returns: [\"Random forest classifier for sentiment analysis\", ...]\n</code></pre>"},{"location":"concepts/queries/#range-based-filtering","title":"Range-Based Filtering","text":"<p>Many query functions support <code>start_position</code> and <code>end_position</code> parameters to filter results to specific ranges within a list. This is useful when:</p> <ul> <li>Different processes appended different portions of data</li> <li>You want to trace lineage for only part of an item</li> <li>You need to understand which code created specific chunks</li> </ul> <pre><code># Get content for positions 100-200\ncontent = vault.query_item_content(\n    \"document_chunks\",\n    start_position=100,\n    end_position=200\n)\n\n# Find parents for only the first 50 items\nparents = vault.query_item_parent(\n    \"embeddings\",\n    start_position=0,\n    end_position=50\n)\n\n# Find which processes modified positions 500-1000\nprocesses = vault.query_item_process(\n    \"training_data\",\n    start_position=500,\n    end_position=1000\n)\n\n# Find children derived from positions 0-100\nchildren = vault.query_item_child(\n    \"source_documents\",\n    start_position=0,\n    end_position=100\n)\n</code></pre>"},{"location":"concepts/setup/","title":"Repository Setup","text":"<p>This guide covers setting up ArangoDB and initializing a TableVault process.</p>"},{"location":"concepts/setup/#local-setup-of-arangodb","title":"Local Setup of ArangoDB","text":"<p>There are various ways to set up an ArangoDB database. For quick development, we use a local Docker container as an example.</p>"},{"location":"concepts/setup/#using-docker","title":"Using Docker","text":"<p>Run the ArangoDB container:</p> <pre><code>docker run -d --name tablevault-arango \\\n    -e ARANGO_ROOT_PASSWORD=passwd \\\n    -p 8529:8529 \\\n    arangodb/arangodb \\\n    arangod --experimental-vector-index=true\n</code></pre> <p>This starts ArangoDB with:</p> <ul> <li>Root password: <code>passwd</code></li> <li>Port: <code>8529</code></li> <li>Container name: <code>tablevault-arango</code></li> </ul> <p>You can verify the database is running by visiting <code>http://localhost:8529</code> in your browser.</p>"},{"location":"concepts/setup/#setting-up-a-tablevault-process","title":"Setting Up a TableVault Process","text":"<p>To interact with a TableVault repository, you must create a <code>Vault</code> object. The Vault represents a tracked process within a Python script or notebook.</p>"},{"location":"concepts/setup/#basic-initialization","title":"Basic Initialization","text":"<pre><code>from tablevault import Vault\n\nvault = Vault(\n    user_id=\"my_user\",\n    process_name=\"experiment_01\"\n)\n</code></pre> <p>Unique Process Name</p> <p>Processes are considered a unique type of item list. The process name is user-defined but must be unique among all item lists in a TableVault repository.</p>"},{"location":"concepts/setup/#full-initialization-with-custom-parameters","title":"Full Initialization with Custom Parameters","text":"<pre><code>from tablevault import Vault\n\nvault = Vault(\n    user_id=\"my_user\",\n    process_name=\"experiment_01\",\n    parent_process_name=\"\",           # Name of parent process (if spawned)\n    parent_process_index=0,           # Index within parent process\n    arango_url=\"http://localhost:8529\",\n    arango_db=\"tablevault\",\n    arango_username=\"tablevault_user\",\n    arango_password=\"tablevault_password\",\n    new_arango_db=True,               # Create new database (drops existing)\n    arango_root_username=\"root\",\n    arango_root_password=\"passwd\",\n    description_embedding_size=1024,\n    log_file_location=\"~/.tablevault/logs/\"\n)\n</code></pre>"},{"location":"concepts/setup/#parameter-reference","title":"Parameter Reference","text":"Parameter Description <code>user_id</code> Your unique identifier <code>process_name</code> Unique name for this process <code>parent_process_name</code> Parent process name (for spawned processes) <code>parent_process_index</code> Index in parent process <code>arango_url</code> ArangoDB server URL <code>arango_db</code> Database name to use <code>arango_username</code> Database username <code>arango_password</code> Database password <code>new_arango_db</code> If <code>True</code>, creates a fresh database <code>arango_root_username</code> Root username for database creation <code>arango_root_password</code> Root password for database creation <code>description_embedding_size</code> Dimension for description embeddings <code>log_file_location</code> Directory for log files <p>Database Creation</p> <p>When <code>new_arango_db=True</code>, the existing database with that name will be dropped and recreated. Set this to <code>False</code> when connecting to an existing TableVault repository.</p>"},{"location":"concepts/setup/#singleton-behavior","title":"Singleton Behavior","text":"<p>The <code>Vault</code> class is a singleton. Only one vault can be active per Python process. Subsequent calls with the same initialization parameters return the same Vault object:</p> <pre><code># First call creates the vault\nvault1 = Vault(user_id=\"user1\", process_name=\"process1\")\n\n# Second call with same params returns the same object\nvault2 = Vault(user_id=\"user1\", process_name=\"process1\")\n\nassert vault1 is vault2  # True\n</code></pre> <p>Attempting to create a vault with different parameters raises an error:</p> <pre><code>vault1 = Vault(user_id=\"user1\", process_name=\"process1\")\nvault2 = Vault(user_id=\"user1\", process_name=\"process2\")  # RuntimeError!\n</code></pre>"},{"location":"concepts/setup/#automatic-code-tracking","title":"Automatic Code Tracking","text":"<p>Once a Vault is created, TableVault automatically tracks executed code:</p> <ul> <li>In Python scripts: The entire script is stored as one data item in a process list</li> <li>In Jupyter notebooks: Each executed cell is stored as a separate data item (in order)</li> </ul> <p>This tracking enables querying items by the code that created them.</p>"},{"location":"concepts/setup/#advanced-information","title":"Advanced Information","text":""},{"location":"concepts/setup/#connecting-to-an-existing-repository","title":"Connecting to an Existing Repository","text":"<p>To connect to an existing TableVault database without dropping it:</p> <pre><code>vault = Vault(\n    user_id=\"my_user\",\n    process_name=\"analysis_process\",\n    new_arango_db=False,  # Don't drop existing database\n    arango_db=\"tablevault\",\n    arango_url=\"http://localhost:8529\",\n    arango_username=\"tablevault_user\",\n    arango_password=\"tablevault_password\"\n)\n</code></pre>"},{"location":"concepts/setup/#custom-embedding-dimensions","title":"Custom Embedding Dimensions","text":"<p>The <code>description_embedding_size</code> parameter defines the embedding size for all descriptions of item lists in the TableVault repository. Set it based on your chosen embedding model.</p> <pre><code>vault = Vault(\n    user_id=\"my_user\",\n    process_name=\"bert_experiment\",\n    description_embedding_size=768  # Match your model's output\n)\n</code></pre>"},{"location":"concepts/types/","title":"Types and Type Queries","text":"<p>TableVault supports five list categories: file lists, document lists, embedding lists, record lists, and process lists.</p> <p>You can query each type directly through the TableVault API. This page summarizes the characteristics of each type and the corresponding query patterns.</p>"},{"location":"concepts/types/#data-types","title":"Data Types","text":""},{"location":"concepts/types/#file-list","title":"File List","text":"<p>Each file data item contains a location that represents the access location of an external file. Note that TableVault does not verify this location internally, and any string is accepted.</p> <pre><code># Create a file list\nvault.create_file_list(\"trained_models\")\n\n# Append file references\nvault.append_file(\"trained_models\", \"models/classifier_v1.pkl\")\nvault.append_file(\"trained_models\", \"models/classifier_v2.pkl\")\n\n# Append with input dependencies (links to other items)\nvault.append_file(\n    \"trained_models\",\n    \"models/ensemble.pkl\",\n    input_items={\"training_data\": [0, 100]}  # depends on positions 0-100 of training_data\n)\n</code></pre>"},{"location":"concepts/types/#document-list","title":"Document List","text":"<p>Each document data item contains a text string that represents textual content. Documents are useful for storing text chunks, logs, or any string-based data.</p> <pre><code># Create a document list\nvault.create_document_list(\"research_notes\")\n\n# Append documents\nvault.append_document(\"research_notes\", \"Initial experiment showed 95% accuracy.\")\nvault.append_document(\"research_notes\", \"Second run with more data: 97% accuracy.\")\n\n# Append with specific position tracking\nvault.append_document(\n    \"research_notes\",\n    \"Final results summary.\",\n    index=2,\n    start_position=100\n)\n</code></pre>"},{"location":"concepts/types/#embedding-list","title":"Embedding List","text":"<p>Each embedding list consists of one-dimensional arrays of floats with a fixed dimension. All embeddings in a list must have the same dimensionality.</p> <pre><code># Create an embedding list (specify dimension)\nvault.create_embedding_list(\"document_embeddings\", ndim=1024)\n\n# Append embeddings\nembedding_vector = [0.1, 0.2, ...]  # 1024-dimensional vector\nvault.append_embedding(\"document_embeddings\", embedding_vector)\n\n# Append with input dependencies\nvault.append_embedding(\n    \"document_embeddings\",\n    another_embedding,\n    input_items={\"research_notes\": [0, 1]},  # embedding derived from document at position 0-1\n    build_idx=True  # rebuild vector index for similarity search\n)\n</code></pre>"},{"location":"concepts/types/#record-list","title":"Record List","text":"<p>Each record list stores structured data as dictionaries with predefined column names. Records are useful for storing tabular or structured metadata.</p> <pre><code># Create a record list with column names\nvault.create_record_list(\"experiment_results\", column_names=[\"model\", \"accuracy\", \"params\"])\n\n# Append records\nvault.append_record(\"experiment_results\", {\n    \"model\": \"random_forest\",\n    \"accuracy\": 0.95,\n    \"params\": {\"n_estimators\": 100, \"max_depth\": 10}\n})\n\nvault.append_record(\"experiment_results\", {\n    \"model\": \"xgboost\",\n    \"accuracy\": 0.97,\n    \"params\": {\"learning_rate\": 0.1, \"n_estimators\": 200}\n})\n</code></pre>"},{"location":"concepts/types/#process-list","title":"Process List","text":"<p>Process lists are special lists that are automatically generated by TableVault for each process instance. When you initialize a Vault object in a Python process, subsequently executed code is stored within a process list. In a Python script, the entire code file is stored as one data item in a process list. In a Python notebook, each executed cell is stored as a data item (in order).</p> <p>The process parent of a new process list is explicitly defined during initialization of the Vault object with <code>parent_process_name</code> and <code>parent_process_index</code>. You should define those values if one process is being created by another executing process.</p>"},{"location":"concepts/types/#type-search","title":"Type Search","text":"<p>For each data type in a TableVault repository, you can search over all stored data items of that type. All query methods support common filtering parameters:</p> <ul> <li><code>description_embedding</code>: Embedding vector for similarity search on item descriptions</li> <li><code>description_text</code>: Text to search in item descriptions</li> <li><code>code_text</code>: Text to search in the process code that created/modified the items</li> <li><code>filtered</code>: List of item names to restrict search to</li> </ul>"},{"location":"concepts/types/#file-list-queries","title":"File List Queries","text":"<p>Query file items by their descriptions or the code that created them.</p> <pre><code># Query all file items\nresults = vault.query_file_list()\n\n# Query with description text filter\nresults = vault.query_file_list(description_text=\"classifier model\")\n\n# Query with code text filter (find files created by specific code)\nresults = vault.query_file_list(code_text=\"train_model\")\n\n# Query with description embedding similarity\nresults = vault.query_file_list(description_embedding=query_vector)\n\n# Restrict search to specific file lists\nresults = vault.query_file_list(\n    description_text=\"model\",\n    filtered=[\"trained_models\", \"checkpoints\"]\n)\n</code></pre>"},{"location":"concepts/types/#document-list-queries","title":"Document List Queries","text":"<p>Query document items by their text content, descriptions, or creating code.</p> <pre><code># Query by document text content\nresults = vault.query_document_list(document_text=\"accuracy\")\n\n# Query with multiple filters\nresults = vault.query_document_list(\n    document_text=\"experiment\",\n    description_text=\"research\",\n    code_text=\"analyze\"\n)\n\n# Restrict to specific document lists\nresults = vault.query_document_list(\n    document_text=\"results\",\n    filtered=[\"research_notes\", \"logs\"]\n)\n</code></pre>"},{"location":"concepts/types/#embedding-list-queries","title":"Embedding List Queries","text":"<p>Query embedding items by vector similarity. Supports both exact and approximate nearest neighbor search.</p> <pre><code># Query by embedding similarity (exact search)\nquery_embedding = [0.1, 0.2, ...]  # must match list dimensionality\nresults = vault.query_embedding_list(embedding=query_embedding)\n\n# Use approximate search for faster results on large datasets\nresults = vault.query_embedding_list(\n    embedding=query_embedding,\n    use_approx=True\n)\n\n# Combine with description and code filters\nresults = vault.query_embedding_list(\n    embedding=query_embedding,\n    description_text=\"document embedding\",\n    code_text=\"encode_text\"\n)\n\n# Restrict to specific embedding lists\nresults = vault.query_embedding_list(\n    embedding=query_embedding,\n    filtered=[\"document_embeddings\", \"image_embeddings\"]\n)\n</code></pre>"},{"location":"concepts/types/#record-list-queries","title":"Record List Queries","text":"<p>Query record items by text content within the records.</p> <pre><code># Query by record text content\nresults = vault.query_record_list(record_text=\"random_forest\")\n\n# Query with multiple filters\nresults = vault.query_record_list(\n    record_text=\"accuracy\",\n    description_text=\"experiment\",\n    code_text=\"evaluate\"\n)\n\n# Restrict to specific record lists\nresults = vault.query_record_list(\n    record_text=\"xgboost\",\n    filtered=[\"experiment_results\"]\n)\n</code></pre>"},{"location":"concepts/types/#process-list-queries","title":"Process List Queries","text":"<p>Query process items by code content, parent process code, or descriptions.</p> <pre><code># Query by code text in process\nresults = vault.query_process_list(code_text=\"import pandas\")\n\n# Query by parent process code\nresults = vault.query_process_list(parent_code_text=\"spawn_worker\")\n\n# Query with description similarity\nresults = vault.query_process_list(\n    description_embedding=query_vector,\n    description_text=\"training pipeline\"\n)\n\n# Combine multiple filters\nresults = vault.query_process_list(\n    code_text=\"model.fit\",\n    parent_code_text=\"hyperparameter_search\",\n    filtered=[\"training_process_1\", \"training_process_2\"]\n)\n</code></pre>"},{"location":"other/about/","title":"About TableVault","text":""},{"location":"other/about/#citations-and-papers","title":"Citations and Papers","text":"<p>If you'd like to cite the TableVault project, you can use:</p> PaperBibtex <p>TableVault: Managing Dynamic Data Collections for LLM-Augmented Workflows Jinjin Zhao &amp; Sanjay Krishnan NOVAS Workshop @ SIGMOD 2025</p> <pre><code>@misc{zhao2025tablevaultmanagingdynamicdata,\n    title={TableVault: Managing Dynamic Data Collections for LLM-Augmented Workflows}, \n    author={Jinjin Zhao and Sanjay Krishnan},\n    year={2025},\n    eprint={2506.18257},\n    archivePrefix={arXiv},\n    primaryClass={cs.DB},\n    url={https://arxiv.org/abs/2506.18257}, \n}\n</code></pre>"},{"location":"other/about/#contact","title":"Contact","text":"<p>You can reach out through email: j2zhao@uchicago.edu.</p>"},{"location":"other/tutorial/","title":"Basic Example","text":"<p>This tutorial demonstrates the core concepts of TableVault through a practical example: building a document processing pipeline with searchable embeddings.</p>"},{"location":"other/tutorial/#step-1-install-dependencies","title":"Step 1: Install Dependencies","text":"<p>First, install TableVault.</p> <pre><code>!pip install tablevault\n</code></pre>"},{"location":"other/tutorial/#step-2-setup-arangodb","title":"Step 2: Setup ArangoDB","text":"<p>Run ArangoDB locally using Docker with vector index support enabled.</p> <pre><code>import subprocess\nsubprocess.run([\n    \"docker\", \"run\", \"-d\",\n    \"--name\", \"arangodb\",\n    \"-e\", \"ARANGO_ROOT_PASSWORD=rootpassword\",\n    \"-p\", \"8529:8529\",\n    \"arangodb:3.12\",\n    \"arangod\", \"--experimental-vector-index=true\"\n], check=True)\n</code></pre> <p>Once ArangoDB is running, you can explore your database using the built-in web UI at http://localhost:8529. Log in with username <code>root</code> and password <code>rootpassword</code> to browse collections, run queries, and inspect your data like a typical database.</p> <p>If the command fails with a port binding error, port 8529 is already in use. Find and stop the conflicting process before continuing:</p> <pre><code>lsof -i :8529          # find what is using the port\ndocker stop &lt;name&gt;     # if it is a Docker container\n</code></pre> <p>Verify ArangoDB is running:</p> <pre><code>from arango import ArangoClient\nfrom arango.exceptions import ArangoError\n\nclient = ArangoClient(hosts=\"http://localhost:8529\")\n\ntry:\n    sys_db = client.db(\"_system\", username=\"root\", password=\"rootpassword\")\n    info = sys_db.version()\n    version = info.get(\"version\") if isinstance(info, dict) else info\n    print(f\"ArangoDB is ready: {version}\")\nexcept ArangoError as exc:\n    raise RuntimeError(\"ArangoDB started, but auth failed. Check root password setup.\") from exc\n</code></pre>"},{"location":"other/tutorial/#step-3-initialize-the-vault","title":"Step 3: Initialize the Vault","text":"<p>Create a TableVault instance connected to your ArangoDB. The <code>process_name</code> identifies this run: all data written through this vault is attributed to the <code>document_pipeline</code> process, making it easy to trace where each item came from later.</p> <pre><code>from tablevault import Vault\n\n# Create a new TableVault process\nvault = Vault(\n    user_id=\"tutorial_user\",\n    process_name=\"document_pipeline\",\n    arango_url=\"http://localhost:8529\",\n    arango_db=\"tutorial_db\",\n    new_arango_db=True,  # Start fresh\n    arango_root_password=\"rootpassword\"\n)\n\nprint(\"Vault initialized successfully!\")\n</code></pre>"},{"location":"other/tutorial/#step-4-create-item-lists","title":"Step 4: Create Item Lists","text":"<p>TableVault organizes data into typed lists:</p> <ul> <li>Document lists: Store text content</li> <li>Embedding lists: Store vector embeddings</li> <li>Record lists: Store structured metadata</li> </ul> <p>Each list stores items at sequential integer positions. Items across lists can be linked by position range to track lineage. For example, recording that embedding position 2 was derived from document positions 2\u20133.</p> <pre><code># Create a document list for storing text chunks\nvault.create_document_list(\"research_papers\")\n\n# Create an embedding list (using 384-dim for this example)\nEMBEDDING_DIM = 384\nvault.create_embedding_list(\"paper_embeddings\", ndim=EMBEDDING_DIM)\n\n# Create a record list for metadata\nvault.create_record_list(\"paper_metadata\", column_names=[\"title\", \"author\", \"chunk_id\"])\n\nprint(\"Item lists created!\")\n</code></pre>"},{"location":"other/tutorial/#step-5-add-documents-and-track-lineage","title":"Step 5: Add Documents and Track Lineage","text":"<p>We'll add sample documents and their embeddings, tracking the lineage between them. The <code>input_items</code> argument on <code>append_embedding</code> records which source positions the embedding was derived from, forming an explicit link that can be queried later.</p> <pre><code># Sample document chunks\ndocuments = [\n    \"Machine learning is a subset of artificial intelligence.\",\n    \"Neural networks are inspired by biological neurons.\",\n    \"Deep learning has revolutionized computer vision.\",\n    \"Transformers have changed natural language processing.\",\n]\n\n# Mock embedding function (replace with your actual model like sentence-transformers)\ndef get_embedding(text):\n    import hashlib\n    import random\n\n    seed = int.from_bytes(hashlib.sha256(text.encode()).digest(), \"big\")\n    rng = random.Random(seed)\n    return [rng.random() for _ in range(EMBEDDING_DIM)]\n\nprint(f\"Mock embedding dimension: {len(get_embedding('test'))}\")\n</code></pre> <pre><code># Add documents and their embeddings with lineage tracking\nfor idx, doc in enumerate(documents):\n    # Add document\n    vault.append_document(\"research_papers\", doc)\n\n    # Generate and add embedding with lineage tracking\n    embedding = get_embedding(doc)\n    vault.append_embedding(\n        \"paper_embeddings\",\n        embedding,\n        input_items={\"research_papers\": [idx, idx + 1]},  # Links to source document\n        index_rebuild_count=max(0, len(documents) - 1),  # Force index build for small demo sets\n    )\n\n    # Add metadata\n    vault.append_record(\"paper_metadata\", {\n        \"title\": f\"Paper Section {idx + 1}\",\n        \"author\": \"Tutorial Author\",\n        \"chunk_id\": idx\n    })\n\n    print(f\"Added document {idx + 1}: {doc[:50]}...\")\n\n    # All writes for this item are complete \u2014 safe to stop or pause the process here\n    vault.checkpoint_execution()\n\nhas_index = vault.has_vector_index(EMBEDDING_DIM)\nprint(f\"\\nVector index created: {has_index}\")\nif not has_index:\n    print(\"Vector index was not created; approximate search may be unavailable on this ArangoDB setup.\")\nprint(\"All documents added with lineage tracking!\")\n</code></pre>"},{"location":"other/tutorial/#why-checkpoint_execution-matters","title":"Why <code>checkpoint_execution</code> matters","text":"<p><code>vault.checkpoint_execution()</code> marks a safe boundary at the end of each loop iteration.</p> <ul> <li>Stop or pause requests only take effect at a checkpoint, never mid-write or during a pending API call.</li> <li>Resume also happens at a checkpoint, which keeps pipeline state consistent.</li> </ul>"},{"location":"other/tutorial/#step-6-add-descriptions","title":"Step 6: Add Descriptions","text":"<p>Each item list can have a description: a short text and optional embedding that annotates what the list contains. Descriptions serve two purposes: they make lists self-documenting, and they act as a semantic filter when querying. In Step 9 you will see how <code>description_text</code> narrows a search to only the lists relevant to your query.</p> <pre><code># Add semantic descriptions for queryability\nvault.create_description(\n    \"research_papers\",\n    description=\"Collection of machine learning research paper excerpts\",\n    embedding=get_embedding(\"machine learning research papers\")\n)\n\nvault.create_description(\n    \"paper_embeddings\",\n    description=\"Vector embeddings of research paper text chunks\",\n    embedding=get_embedding(\"document embeddings vectors\")\n)\n\nprint(\"Descriptions added!\")\n</code></pre>"},{"location":"other/tutorial/#step-7-query-content","title":"Step 7: Query Content","text":"<p>Now let's query the stored content.</p> <pre><code># Get all documents\nall_docs = vault.query_item_content(\"research_papers\")\nprint(\"All documents:\")\nfor i, doc in enumerate(all_docs):\n    print(f\"  [{i}]: {doc}\")\n</code></pre> <pre><code># Get specific document by index\nfirst_doc = vault.query_item_content(\"research_papers\", index=0)\nprint(f\"First document: {first_doc}\")\n</code></pre> <pre><code># Get item metadata\nmetadata = vault.query_item_list(\"research_papers\")\nprint(f\"Document list info: {metadata}\")\n</code></pre>"},{"location":"other/tutorial/#step-8-query-lineage","title":"Step 8: Query Lineage","text":"<p>Lineage lets you trace exactly which source data produced each derived item. This is useful for debugging data quality issues, reproducing results, and auditing how your pipeline transformed data over time. You can traverse in either direction: from a derived item back to its sources, or from a source forward to everything derived from it.</p> <pre><code># Find what the embeddings were derived from\nparents = vault.query_item_parent(\"paper_embeddings\")\nprint(f\"Embedding parents: {parents}\")\n</code></pre> <pre><code># Find what was derived from the documents\nchildren = vault.query_item_child(\"research_papers\")\nprint(f\"Document children: {children}\")\n</code></pre> <pre><code># Get specific range lineage\nfirst_embedding_source = vault.query_item_parent(\n    \"paper_embeddings\",\n    start_position=0,\n    end_position=1\n)\nprint(f\"First embedding came from: {first_embedding_source}\")\n</code></pre>"},{"location":"other/tutorial/#step-9-similarity-search","title":"Step 9: Similarity Search","text":"<p>TableVault supports both vector similarity search over embeddings and full-text search over documents. Both query types accept optional filters to narrow the search scope. <code>description_text</code> restricts results to lists whose description matches, and <code>code_text</code> restricts to lists created by processes whose source code contains the given string.</p> <pre><code># Search by embedding similarity\nquery_text = \"artificial intelligence and deep learning\"\nquery_embedding = get_embedding(query_text)\n\n# Find similar embeddings\nsimilar = vault.query_embedding_list(\n    embedding=query_embedding,\n    use_approx=False,\n)\nprint(f\"Similar embeddings: {similar}\")\n</code></pre> <pre><code># Search documents by text\nresults = vault.query_document_list(\n    document_text=\"neural networks\"\n)\nprint(f\"Documents matching 'neural networks': {results}\")\n</code></pre> <p>Combining these filters is especially useful in large vaults with many lists. You can target exactly the data that is semantically relevant and was produced by the right pipeline stage.</p> <pre><code># Filter embedding search by description text\n# Only searches within lists whose description contains \"document embeddings\"\nsimilar_filtered = vault.query_embedding_list(\n    embedding=query_embedding,\n    description_text=\"document embeddings\",\n    use_approx=False,\n)\nprint(f\"Embeddings filtered by description: {similar_filtered}\")\n</code></pre> <pre><code># Filter document search by description text and code text\n# description_text: restricts to lists whose description mentions \"research paper\"\n# code_text: restricts to lists created by processes whose code contains \"append_document\"\nresults_filtered = vault.query_document_list(\n    document_text=\"neural networks\",\n    description_text=\"research paper\",\n    code_text=\"append_document\",\n)\nprint(f\"Documents filtered by description and code: {results_filtered}\")\n</code></pre>"},{"location":"other/tutorial/#step-10-process-queries","title":"Step 10: Process Queries","text":"<p>Every item in TableVault is attributed to the process that created it. Process queries let you audit the full output of a given pipeline run, or find which process was responsible for a particular item. This is useful when you have multiple pipelines writing to the same vault.</p> <pre><code># Find which process created these items\ncreation_process = vault.query_item_creation_process(\"research_papers\")\nprint(f\"Created by process: {creation_process}\")\n</code></pre> <pre><code># Find all items created in this process\nprocess_items = vault.query_process_item(\"document_pipeline\")\nprint(f\"Items in process: {process_items}\")\n</code></pre>"}]}