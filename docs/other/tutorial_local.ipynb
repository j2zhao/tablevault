{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000001",
   "metadata": {},
   "source": [
    "# Basic Example\n",
    "\n",
    "This tutorial demonstrates the core concepts of TableVault through a practical example: building a document processing pipeline with searchable embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000002",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "First, install TableVault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00000001-0000-4000-8000-000000000003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tablevault in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (0.2.2)\n",
      "Requirement already satisfied: python-arango in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from tablevault) (8.2.3)\n",
      "Requirement already satisfied: psutil in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from tablevault) (7.2.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (2.6.1)\n",
      "Requirement already satisfied: requests in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (2.32.5)\n",
      "Requirement already satisfied: requests_toolbelt in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (1.0.0)\n",
      "Requirement already satisfied: PyJWT in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (2.10.1)\n",
      "Requirement already satisfied: setuptools>=42 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (80.9.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.7.1 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (8.7.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from python-arango->tablevault) (25.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from importlib_metadata>=4.7.1->python-arango->tablevault) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from requests->python-arango->tablevault) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from requests->python-arango->tablevault) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jinjinzhao/miniconda3/envs/mlvault/lib/python3.14/site-packages (from requests->python-arango->tablevault) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tablevault"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000004",
   "metadata": {},
   "source": [
    "## Step 2: Setup ArangoDB\n",
    "\n",
    "Run ArangoDB locally using Docker with vector index support enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00000001-0000-4000-8000-000000000005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16d64ae1085a895ef2a1e1b1d9cdf1d28628fdac98775a685394ec5c79b6d45b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['docker', 'run', '-d', '--name', 'arangodb', '-e', 'ARANGO_ROOT_PASSWORD=rootpassword', '-p', '8529:8529', 'arangodb:3.12', 'arangod', '--experimental-vector-index=true'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "subprocess.run([\n",
    "    \"docker\", \"run\", \"-d\",\n",
    "    \"--name\", \"arangodb\",\n",
    "    \"-e\", \"ARANGO_ROOT_PASSWORD=rootpassword\",\n",
    "    \"-p\", \"8529:8529\",\n",
    "    \"arangodb:3.12\",\n",
    "    \"arangod\", \"--experimental-vector-index=true\"\n",
    "], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd6df2-5e18-4de9-8ed4-765187ce9092",
   "metadata": {},
   "source": [
    "Once ArangoDB is running, you can explore your database using the built-in web UI at [http://localhost:8529](http://localhost:8529). Log in with username `root` and password `rootpassword` to browse collections, run queries, and inspect your data like a typical database.\n",
    "\n",
    "If the command fails with a port binding error, port 8529 is already in use. Find and stop the conflicting process before continuing:\n",
    "\n",
    "```bash\n",
    "lsof -i :8529          # find what is using the port\n",
    "docker stop <name>     # if it is a Docker container\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000006",
   "metadata": {},
   "source": [
    "Verify ArangoDB is running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00000001-0000-4000-8000-000000000007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArangoDB is ready: 3.12.7-2\n"
     ]
    }
   ],
   "source": [
    "from arango import ArangoClient\n",
    "from arango.exceptions import ArangoError\n",
    "\n",
    "client = ArangoClient(hosts=\"http://localhost:8529\")\n",
    "\n",
    "try:\n",
    "    sys_db = client.db(\"_system\", username=\"root\", password=\"rootpassword\")\n",
    "    info = sys_db.version()\n",
    "    version = info.get(\"version\") if isinstance(info, dict) else info\n",
    "    print(f\"ArangoDB is ready: {version}\")\n",
    "except ArangoError as exc:\n",
    "    raise RuntimeError(\"ArangoDB started, but auth failed. Check root password setup.\") from exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000008",
   "metadata": {},
   "source": "## Step 3: Initialize the Vault\n\nCreate a TableVault instance connected to your ArangoDB. The `process_name` identifies this run \u2014 all data written through this vault is attributed to the `document_pipeline` process, making it easy to trace where each item came from later."
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00000001-0000-4000-8000-000000000009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vault initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from tablevault import Vault\n",
    "\n",
    "# Create a new TableVault process\n",
    "vault = Vault(\n",
    "    user_id=\"tutorial_user\",\n",
    "    process_name=\"document_pipeline\",\n",
    "    arango_url=\"http://localhost:8529\",\n",
    "    arango_db=\"tutorial_db\",\n",
    "    new_arango_db=True,  # Start fresh\n",
    "    arango_root_password=\"rootpassword\"\n",
    ")\n",
    "\n",
    "print(\"Vault initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000010",
   "metadata": {},
   "source": "## Step 4: Create Item Lists\n\nTableVault organizes data into typed lists:\n\n**Document lists**: Store text content\n**Embedding lists**: Store vector embeddings\n**Record lists**: Store structured metadata\n\nEach list stores items at sequential integer positions. Items across lists can be linked by position range to track lineage \u2014 for example, recording that embedding position 2 was derived from document positions 2\u20133."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00000001-0000-4000-8000-000000000011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Item lists created!\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a document list for storing text chunks\n",
    "vault.create_document_list(\"research_papers\")\n",
    "\n",
    "# Create an embedding list (using 384-dim for this example)\n",
    "EMBEDDING_DIM = 384\n",
    "vault.create_embedding_list(\"paper_embeddings\", ndim=EMBEDDING_DIM)\n",
    "\n",
    "# Create a record list for metadata\n",
    "vault.create_record_list(\"paper_metadata\", column_names=[\"title\", \"author\", \"chunk_id\"])\n",
    "\n",
    "print(\"Item lists created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000012",
   "metadata": {},
   "source": "## Step 5: Add Documents and Track Lineage\n\nWe'll add sample documents and their embeddings, tracking the lineage between them. The `input_items` argument on `append_embedding` records which source positions the embedding was derived from, forming an explicit link that can be queried later."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00000001-0000-4000-8000-000000000013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Mock embedding dimension: 384\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample document chunks\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Neural networks are inspired by biological neurons.\",\n",
    "    \"Deep learning has revolutionized computer vision.\",\n",
    "    \"Transformers have changed natural language processing.\",\n",
    "]\n",
    "\n",
    "# Mock embedding function (replace with your actual model like sentence-transformers)\n",
    "def get_embedding(text):\n",
    "    import hashlib\n",
    "    import random\n",
    "\n",
    "    seed = int.from_bytes(hashlib.sha256(text.encode()).digest(), \"big\")\n",
    "    rng = random.Random(seed)\n",
    "    return [rng.random() for _ in range(EMBEDDING_DIM)]\n",
    "\n",
    "print(f\"Mock embedding dimension: {len(get_embedding('test'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00000001-0000-4000-8000-000000000014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Added document 1: Machine learning is a subset of artificial intelli...\n",
      "Added document 2: Neural networks are inspired by biological neurons...\n",
      "Added document 3: Deep learning has revolutionized computer vision....\n",
      "Added document 4: Transformers have changed natural language process...\n",
      "\n",
      "Vector index created: True\n",
      "All documents added with lineage tracking!\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add documents and their embeddings with lineage tracking\n",
    "for idx, doc in enumerate(documents):\n",
    "    # Add document\n",
    "    vault.append_document(\"research_papers\", doc)\n",
    "\n",
    "    # Generate and add embedding with lineage tracking\n",
    "    embedding = get_embedding(doc)\n",
    "    vault.append_embedding(\n",
    "        \"paper_embeddings\",\n",
    "        embedding,\n",
    "        input_items={\"research_papers\": [idx, idx + 1]},  # Links to source document\n",
    "        index_rebuild_count=max(0, len(documents) - 1),  # Force index build for small demo sets\n",
    "    )\n",
    "\n",
    "    # Add metadata\n",
    "    vault.append_record(\"paper_metadata\", {\n",
    "        \"title\": f\"Paper Section {idx + 1}\",\n",
    "        \"author\": \"Tutorial Author\",\n",
    "        \"chunk_id\": idx\n",
    "    })\n",
    "\n",
    "    print(f\"Added document {idx + 1}: {doc[:50]}...\")\n",
    "\n",
    "    # All writes for this item are complete \u2014 safe to stop or pause the process here\n",
    "    vault.checkpoint_execution()\n",
    "\n",
    "has_index = vault.has_vector_index(EMBEDDING_DIM)\n",
    "print(f\"\\nVector index created: {has_index}\")\n",
    "if not has_index:\n",
    "    print(\"Vector index was not created; approximate search may be unavailable on this ArangoDB setup.\")\n",
    "print(\"All documents added with lineage tracking!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d233a-6906-44d7-bebc-451bb724141e",
   "metadata": {},
   "source": "### Why `checkpoint_execution` matters\n\n`vault.checkpoint_execution()` marks a safe boundary at the end of each loop iteration.\n\nStop/pause behavior: requests only take effect at a checkpoint, never mid-write or during a pending API call.\nResume behavior: resume also happens at a checkpoint, which keeps pipeline state consistent.\n\nWithout checkpoints, stop/pause requests can be deferred indefinitely."
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000015",
   "metadata": {},
   "source": "## Step 6: Add Descriptions\n\nEach item list can have a description \u2014 a short text and optional embedding that annotates what the list contains. Descriptions serve two purposes: they make lists self-documenting, and they act as a semantic filter when querying. In Step 9 you will see how `description_text` narrows a search to only the lists relevant to your query."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00000001-0000-4000-8000-000000000016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Descriptions added!\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add semantic descriptions for queryability\n",
    "vault.create_description(\n",
    "    \"research_papers\",\n",
    "    description=\"Collection of machine learning research paper excerpts\",\n",
    "    embedding=get_embedding(\"machine learning research papers\")\n",
    ")\n",
    "\n",
    "vault.create_description(\n",
    "    \"paper_embeddings\",\n",
    "    description=\"Vector embeddings of research paper text chunks\",\n",
    "    embedding=get_embedding(\"document embeddings vectors\")\n",
    ")\n",
    "\n",
    "print(\"Descriptions added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000017",
   "metadata": {},
   "source": [
    "## Step 7: Query Content\n",
    "\n",
    "Now let's query the stored content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00000001-0000-4000-8000-000000000018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "All documents:\n",
      "  [0]: Machine learning is a subset of artificial intelligence.\n",
      "  [1]: Neural networks are inspired by biological neurons.\n",
      "  [2]: Deep learning has revolutionized computer vision.\n",
      "  [3]: Transformers have changed natural language processing.\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all documents\n",
    "all_docs = vault.query_item_content(\"research_papers\")\n",
    "print(\"All documents:\")\n",
    "for i, doc in enumerate(all_docs):\n",
    "    print(f\"  [{i}]: {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00000001-0000-4000-8000-000000000019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "First document: Machine learning is a subset of artificial intelligence.\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get specific document by index\n",
    "first_doc = vault.query_item_content(\"research_papers\", index=0)\n",
    "print(f\"First document: {first_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00000001-0000-4000-8000-000000000020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Document list info: {'_key': 'research_papers', '_id': 'document_list/research_papers', '_rev': '_lGqFMQW--_', 'deleted': -1, 'length': 210, 'n_items': 4, 'name': 'research_papers', 'process_index': 0, 'process_name': 'document_pipeline', 'timestamp': 3}\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get item metadata\n",
    "metadata = vault.query_item_list(\"research_papers\")\n",
    "print(f\"Document list info: {metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000021",
   "metadata": {},
   "source": "## Step 8: Query Lineage\n\nLineage lets you trace exactly which source data produced each derived item. This is useful for debugging data quality issues, reproducing results, and auditing how your pipeline transformed data over time. You can traverse in either direction \u2014 from a derived item back to its sources, or from a source forward to everything derived from it."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00000001-0000-4000-8000-000000000022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Embedding parents: [[3, 4, 'document_list', 'document_list/research_papers', 3, 4], [2, 3, 'document_list', 'document_list/research_papers', 2, 3], [1, 2, 'document_list', 'document_list/research_papers', 1, 2], [0, 1, 'document_list', 'document_list/research_papers', 0, 1]]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find what the embeddings were derived from\n",
    "parents = vault.query_item_parent(\"paper_embeddings\")\n",
    "print(f\"Embedding parents: {parents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00000001-0000-4000-8000-000000000023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Document children: [[3, 4, 'embedding', 'paper_embeddings', 3, 4], [2, 3, 'embedding', 'paper_embeddings', 2, 3], [1, 2, 'embedding', 'paper_embeddings', 1, 2], [0, 1, 'embedding', 'paper_embeddings', 0, 1]]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find what was derived from the documents\n",
    "children = vault.query_item_child(\"research_papers\")\n",
    "print(f\"Document children: {children}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00000001-0000-4000-8000-000000000024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "First embedding came from: []\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get specific range lineage\n",
    "first_embedding_source = vault.query_item_parent(\n",
    "    \"paper_embeddings\",\n",
    "    start_position=0,\n",
    "    end_position=1\n",
    ")\n",
    "print(f\"First embedding came from: {first_embedding_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000025",
   "metadata": {},
   "source": "## Step 9: Similarity Search\n\nTableVault supports both vector similarity search over embeddings and full-text search over documents. Both query types accept optional filters to narrow the search scope: `description_text` restricts results to lists whose description matches, and `code_text` restricts to lists created by processes whose source code contains the given string."
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00000001-0000-4000-8000-000000000026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Similar embeddings: [['paper_embeddings', 3, [], []], ['paper_embeddings', 1, [], []], ['paper_embeddings', 2, [], []], ['paper_embeddings', 0, [], []]]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search by embedding similarity\n",
    "query_text = \"artificial intelligence and deep learning\"\n",
    "query_embedding = get_embedding(query_text)\n",
    "\n",
    "# Find similar embeddings\n",
    "similar = vault.query_embedding_list(\n",
    "    embedding=query_embedding,\n",
    "    use_approx=False,\n",
    ")\n",
    "print(f\"Similar embeddings: {similar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00000001-0000-4000-8000-000000000027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Documents matching 'neural networks': [['research_papers', 1, [], []]]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search documents by text\n",
    "results = vault.query_document_list(\n",
    "    document_text=\"neural networks\"\n",
    ")\n",
    "print(f\"Documents matching 'neural networks': {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c0aa8-1410-4eb0-9a89-9be311999bee",
   "metadata": {},
   "source": [
    "Combining these filters is especially useful in large vaults with many lists: you can target exactly the data that is semantically relevant and was produced by the right pipeline stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c858137c-7628-464c-ba6e-b217e20bd732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Embeddings filtered by description: []\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter embedding search by description text\n",
    "# Only searches within lists whose description contains \"document embeddings\"\n",
    "similar_filtered = vault.query_embedding_list(\n",
    "    embedding=query_embedding,\n",
    "    description_text=\"document embeddings\",\n",
    "    use_approx=False,\n",
    ")\n",
    "print(f\"Embeddings filtered by description: {similar_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f10741f2-7e6a-430b-aa4f-b5357b6cc916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Documents filtered by description and code: [['research_papers', 1, ['research_papers_BASE_DESCRIPT'], [['document_pipeline', 2]]]]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter document search by description text and code text\n",
    "# description_text: restricts to lists whose description mentions \"research paper\"\n",
    "# code_text: restricts to lists created by processes whose code contains \"append_document\"\n",
    "results_filtered = vault.query_document_list(\n",
    "    document_text=\"neural networks\",\n",
    "    description_text=\"research paper\",\n",
    "    code_text=\"append_document\",\n",
    ")\n",
    "print(f\"Documents filtered by description and code: {results_filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00000001-0000-4000-8000-000000000028",
   "metadata": {},
   "source": "## Step 10: Process Queries\n\nEvery item in TableVault is attributed to the process that created it. Process queries let you audit the full output of a given pipeline run, or find which process was responsible for a particular item \u2014 useful when you have multiple pipelines writing to the same vault."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00000001-0000-4000-8000-000000000029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Created by process: [{'process_id': 'process_list/document_pipeline', 'index': 0}]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find which process created these items\n",
    "creation_process = vault.query_item_creation_process(\"research_papers\")\n",
    "print(f\"Created by process: {creation_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00000001-0000-4000-8000-000000000030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---[ TableVault Record ]---\n",
      "Items in process: [{'name': 'paper_embeddings', 'start_position': None, 'end_position': None}, {'name': 'paper_embeddings', 'start_position': 0, 'end_position': 4}, {'name': 'paper_embeddings_BASE_DESCRIPT', 'start_position': None, 'end_position': None}, {'name': 'paper_metadata', 'start_position': None, 'end_position': None}, {'name': 'paper_metadata', 'start_position': 0, 'end_position': 4}, {'name': 'research_papers', 'start_position': None, 'end_position': None}, {'name': 'research_papers', 'start_position': 0, 'end_position': 210}, {'name': 'research_papers_BASE_DESCRIPT', 'start_position': None, 'end_position': None}]\n",
      "---[ TableVault Record ]---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find all items created in this process\n",
    "process_items = vault.query_process_item(\"document_pipeline\")\n",
    "print(f\"Items in process: {process_items}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
